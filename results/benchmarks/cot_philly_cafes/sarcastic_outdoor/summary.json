{
  "type": "ranking",
  "k": 5,
  "hits_at": {
    "1": {
      "mean": 0.34210526315789475,
      "std": 0.0,
      "values": [
        0.34210526315789475
      ]
    },
    "2": {
      "mean": 0.34210526315789475,
      "std": 0.0,
      "values": [
        0.34210526315789475
      ]
    },
    "3": {
      "mean": 0.34210526315789475,
      "std": 0.0,
      "values": [
        0.34210526315789475
      ]
    },
    "4": {
      "mean": 0.34210526315789475,
      "std": 0.0,
      "values": [
        0.34210526315789475
      ]
    },
    "5": {
      "mean": 0.3684210526315789,
      "std": 0.0,
      "values": [
        0.3684210526315789
      ]
    }
  },
  "per_run": [
    {
      "total": 38,
      "k": 5,
      "hits_at": {
        "1": {
          "hits": 13,
          "accuracy": 0.34210526315789475
        },
        "2": {
          "hits": 13,
          "accuracy": 0.34210526315789475
        },
        "3": {
          "hits": 13,
          "accuracy": 0.34210526315789475
        },
        "4": {
          "hits": 13,
          "accuracy": 0.34210526315789475
        },
        "5": {
          "hits": 14,
          "accuracy": 0.3684210526315789
        }
      }
    }
  ],
  "runs": 1,
  "method": "cot",
  "data": "philly_cafes",
  "attack": "sarcastic_outdoor",
  "usage": {
    "total_calls": 38,
    "total_prompt_tokens": 3954655,
    "total_completion_tokens": 130567,
    "total_tokens": 4085222,
    "total_cost_usd": 0.671538,
    "mean_cost_per_run": 0.671538,
    "per_run": [
      {
        "total_calls": 38,
        "total_prompt_tokens": 3954655,
        "total_completion_tokens": 130567,
        "total_tokens": 4085222,
        "total_cost_usd": 0.671538,
        "total_latency_ms": 1388319.29,
        "avg_latency_ms": 36534.72,
        "by_model": {
          "gpt-5-nano": {
            "calls": 38,
            "prompt_tokens": 3954655,
            "completion_tokens": 130567,
            "cost_usd": 0.671538
          }
        }
      }
    ]
  }
}